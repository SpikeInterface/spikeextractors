{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import spikeextractors as se\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties of the in-memory dataset\n",
    "num_channels=7\n",
    "samplerate=30000\n",
    "duration=20\n",
    "num_timepoints=int(samplerate*duration)\n",
    "num_units=5\n",
    "num_events=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a pure-noise timeseries dataset and a linear geometry\n",
    "timeseries=np.random.normal(0,10,(num_channels,num_timepoints))\n",
    "geom=np.zeros((num_channels,2))\n",
    "geom[:,0]=range(num_channels)\n",
    "\n",
    "# Define the in-memory recording extractor\n",
    "RX=se.NumpyRecordingExtractor(timeseries=timeseries,geom=geom,samplerate=samplerate)\n",
    "\n",
    "# Generate some random events\n",
    "times=np.int_(np.sort(np.random.uniform(0,num_timepoints,num_events)))\n",
    "labels=np.random.randint(1,num_units+1,size=num_events)\n",
    "    \n",
    "# Define the in-memory sorting extractor\n",
    "SX=se.NumpySortingExtractor()\n",
    "for k in range(1,num_units+1):\n",
    "    times_k=times[np.where(labels==k)[0]]\n",
    "    SX.addUnit(unit_id=k,times=times_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = 0\n",
    "for unit_id in SX.getUnitIds():\n",
    "    SX.setUnitSpikeFeatures(unit_id, feature_name='f_int', value=range(spikes, spikes + len(SX.getUnitSpikeTrain(unit_id))))\n",
    "    spikes += len(SX.getUnitSpikeTrain(unit_id))\n",
    "    \n",
    "spikes = 0\n",
    "for unit_id in SX.getUnitIds():\n",
    "    SX.setUnitSpikeFeatures(unit_id, feature_name='f_float', value=np.arange(float(spikes) + .1, float(spikes + len(SX.getUnitSpikeTrain(unit_id) + .1))))\n",
    "    spikes += len(SX.getUnitSpikeTrain(unit_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  9 10]\n",
      "[ 8.1  9.1 10.1]\n"
     ]
    }
   ],
   "source": [
    "print(SX.getUnitSpikeFeatures(3, 'f_int'))\n",
    "print(SX.getUnitSpikeFeatures(3, 'f_float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit ids = [1, 2, 3, 4, 5]\n",
      "Num. events for unit 1 = 5\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the API for extracting information\n",
    "print('Unit ids = {}'.format(SX.getUnitIds()))\n",
    "st=SX.getUnitSpikeTrain(unit_id=1)\n",
    "print('Num. events for unit 1 = {}'.format(len(st)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can curate the results using a CuratedSortingExtractor\n",
    "\n",
    "CSX = se.CuratedSortingExtractor(parent_sorting=SX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  9 10]\n",
      "[ 8.1  9.1 10.1]\n"
     ]
    }
   ],
   "source": [
    "print(CSX.getUnitSpikeFeatures(3, 'f_int'))\n",
    "print(CSX.getUnitSpikeFeatures(3, 'f_float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[206907 220517 331138 430220 574290]\n",
      "[327869 436875 525257]\n",
      "[183155 398518 507142]\n",
      "[210132 220886 445947 477836]\n",
      "[168716 256926 272397 318528 470153]\n"
     ]
    }
   ],
   "source": [
    "for unit_id in CSX.getUnitIds():\n",
    "    print(CSX.getUnitSpikeTrain(unit_id=unit_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curated Unit Ids: [1, 2, 3, 4, 5]\n",
      "Original Unit Ids: [1, 2, 3, 4, 5]\n",
      "Curated ST: [206907 220517 331138 430220 574290]\n",
      "Original ST: [206907 220517 331138 430220 574290]\n"
     ]
    }
   ],
   "source": [
    "print(\"Curated Unit Ids: \" + str(CSX.getUnitIds()))\n",
    "print(\"Original Unit Ids: \" + str(SX.getUnitIds()))\n",
    "\n",
    "print(\"Curated ST: \" + str(CSX.getUnitSpikeTrain(1)))\n",
    "print(\"Original ST: \" + str(SX.getUnitSpikeTrain(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curated Unit Ids: [2, 3, 4, 5, 6, 7]\n",
      "Original Spike Train: [206907 220517 331138 430220 574290]\n",
      "Split Spike Train 1: [206907 220517]\n",
      "Split Spike Train 2: [331138 430220 574290]\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "^-------1\n",
      "\n",
      "7\n",
      "^-------1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lets split one unit from the sorting result (this could be two units incorrectly clustered as one)\n",
    "\n",
    "CSX.splitUnit(unit_id=1, indices=[0, 1])\n",
    "print(\"Curated Unit Ids: \" + str(CSX.getUnitIds()))\n",
    "print(\"Original Spike Train: \" + str(SX.getUnitSpikeTrain(1)))\n",
    "print(\"Split Spike Train 1: \" + str(CSX.getUnitSpikeTrain(6)))\n",
    "print(\"Split Spike Train 2: \" + str(CSX.getUnitSpikeTrain(7)))\n",
    "for unit_id in CSX.getUnitIds():\n",
    "    CSX.printCurationTree(unit_id=unit_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curated Spike Train: [206907 220517 331138 430220 574290]\n",
      "Original Spike Train: [206907 220517 331138 430220 574290]\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "8\n",
      "^-------6\n",
      "\t^-------1\n",
      "^-------7\n",
      "\t^-------1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If the split was incorrect, we can always merge the two units back together\n",
    "CSX.mergeUnits(unit_ids=[6, 7])\n",
    "print(\"Curated Spike Train: \" + str(CSX.getUnitSpikeTrain(8)))\n",
    "print(\"Original Spike Train: \" + str(SX.getUnitSpikeTrain(1)))\n",
    "for unit_id in CSX.getUnitIds():\n",
    "    CSX.printCurationTree(unit_id=unit_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also exclude units, so let's get rid of 8 since we are just confused about this unit\n",
    "CSX.excludeUnits(unit_ids=[8])\n",
    "for unit_id in CSX.getUnitIds():\n",
    "    CSX.printCurationTree(unit_id=unit_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curated Unit Ids: [2, 5, 9]\n",
      "Merged Spike Train: [183155 210132 220886 398518 445947 477836 507142]\n",
      "Original Spike Trains concatenated: [183155 210132 220886 398518 445947 477836 507142]\n",
      "\n",
      "Curation Tree\n",
      "2\n",
      "\n",
      "5\n",
      "\n",
      "9\n",
      "^-------3\n",
      "^-------4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now let's merge 3 and 4 together (This will create a new unit which encapsulates both previous units)\n",
    "CSX.mergeUnits(unit_ids=[3, 4])\n",
    "print(\"Curated Unit Ids: \" + str(CSX.getUnitIds()))\n",
    "print(\"Merged Spike Train: \" + str(CSX.getUnitSpikeTrain(9)))\n",
    "print(\"Original Spike Trains concatenated: \" + str(np.sort(np.concatenate((SX.getUnitSpikeTrain(3), SX.getUnitSpikeTrain(4))))))\n",
    "print(\"\\nCuration Tree\")\n",
    "for unit_id in CSX.getUnitIds():\n",
    "    CSX.printCurationTree(unit_id=unit_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curated Unit Ids: [5, 10]\n",
      "Merged Spike Train: [183155 210132 220886 327869 398518 436875 445947 477836 507142 525257]\n",
      "Original Spike Trains concatenated: [183155 210132 220886 327869 398518 436875 445947 477836 507142 525257]\n",
      "\n",
      "Curation Tree\n",
      "5\n",
      "\n",
      "10\n",
      "^-------2\n",
      "^-------9\n",
      "\t^-------3\n",
      "\t^-------4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now let's merge 2 and 6 together\n",
    "\n",
    "CSX.mergeUnits(unit_ids=[2, 9])\n",
    "print(\"Curated Unit Ids: \" + str(CSX.getUnitIds()))\n",
    "print(\"Merged Spike Train: \" + str(CSX.getUnitSpikeTrain(10)))\n",
    "merged_spike_train = []\n",
    "for unit_id in SX.getUnitIds():\n",
    "    if(unit_id != 1 and unit_id != 5):\n",
    "        merged_spike_train.append(SX.getUnitSpikeTrain(unit_id))\n",
    "merged_spike_train = np.asarray(merged_spike_train)\n",
    "merged_spike_train = np.sort(np.concatenate(merged_spike_train).ravel())\n",
    "print(\"Original Spike Trains concatenated: \" + str(merged_spike_train))\n",
    "print(\"\\nCuration Tree\")\n",
    "for unit_id in CSX.getUnitIds():\n",
    "    CSX.printCurationTree(unit_id=unit_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curated Unit Ids: [10, 11, 12]\n",
      "Original Spike Train: [168716 256926 272397 318528 470153]\n",
      "Split Spike Train 1: [168716 256926]\n",
      "Split Spike Train 2: [272397 318528 470153]\n",
      "\n",
      "Curation Tree\n",
      "10\n",
      "^-------2\n",
      "^-------9\n",
      "\t^-------3\n",
      "\t^-------4\n",
      "\n",
      "11\n",
      "^-------5\n",
      "\n",
      "12\n",
      "^-------5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now let's split unit 5 with given indices\n",
    "\n",
    "CSX.splitUnit(unit_id=5, indices=[0, 1])\n",
    "print(\"Curated Unit Ids: \" + str(CSX.getUnitIds()))\n",
    "print(\"Original Spike Train: \" + str(SX.getUnitSpikeTrain(5)))\n",
    "print(\"Split Spike Train 1: \" + str(CSX.getUnitSpikeTrain(11)))\n",
    "print(\"Split Spike Train 2: \" + str(CSX.getUnitSpikeTrain(12)))\n",
    "print(\"\\nCuration Tree\")\n",
    "for unit_id in CSX.getUnitIds():\n",
    "    CSX.printCurationTree(unit_id=unit_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curated Unit Ids: [12, 13]\n",
      "Merged Spike Train: [168716 183155 210132 220886 256926 327869 398518 436875 445947 477836\n",
      " 507142 525257]\n",
      "Original Spike Train: [168716 183155 210132 220886 256926 327869 398518 436875 445947 477836\n",
      " 507142 525257]\n",
      "\n",
      "Curation Tree\n",
      "12\n",
      "^-------5\n",
      "\n",
      "13\n",
      "^-------10\n",
      "\t^-------2\n",
      "\t^-------9\n",
      "\t\t^-------3\n",
      "\t\t^-------4\n",
      "^-------11\n",
      "\t^-------5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Finally, we can merge units 7 and 8\n",
    "\n",
    "CSX.mergeUnits(unit_ids=[10, 11])\n",
    "print(\"Curated Unit Ids: \" + str(CSX.getUnitIds()))\n",
    "print(\"Merged Spike Train: \" + str(CSX.getUnitSpikeTrain(13)))\n",
    "original_spike_train = (np.sort(np.concatenate((SX.getUnitSpikeTrain(3), SX.getUnitSpikeTrain(4), SX.getUnitSpikeTrain(2), SX.getUnitSpikeTrain(5)[np.asarray([0,1])]))))\n",
    "print(\"Original Spike Train: \" + str(original_spike_train))\n",
    "print(\"\\nCuration Tree\")\n",
    "for unit_id in CSX.getUnitIds():\n",
    "    CSX.printCurationTree(unit_id=unit_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the input/output in the MountainSort format\n",
    "se.MdaRecordingExtractor.writeRecording(recording=RX,save_path='sample_mountainsort_dataset')\n",
    "se.MdaSortingExtractor.writeSorting(sorting=CSX,save_path='sample_mountainsort_dataset/firings_true.mda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read this dataset with the Mda input extractor (we can now have a normal sorting extractor with our curations)\n",
    "RX2=se.MdaRecordingExtractor(dataset_directory='sample_mountainsort_dataset')\n",
    "SX2=se.MdaSortingExtractor(firings_file='sample_mountainsort_dataset/firings_true.mda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Unit Ids: [12 13]\n",
      "New Unit Spike Train: [168716 183155 210132 220886 256926 327869 398518 436875 445947 477836\n",
      " 507142 525257]\n",
      "Previous Curated Unit Spike Train: [168716 183155 210132 220886 256926 327869 398518 436875 445947 477836\n",
      " 507142 525257]\n"
     ]
    }
   ],
   "source": [
    "print(\"New Unit Ids: \" + str(SX2.getUnitIds()))\n",
    "print(\"New Unit Spike Train: \" + str(SX2.getUnitSpikeTrain(13)))\n",
    "print(\"Previous Curated Unit Spike Train: \" + str(CSX.getUnitSpikeTrain(13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 13]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSX.getUnitIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSX.getUnitSpikeFeatureNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spikeinterface]",
   "language": "python",
   "name": "conda-env-spikeinterface-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
